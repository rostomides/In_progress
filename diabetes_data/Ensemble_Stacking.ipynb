{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before loading the following dataset, be sure to run the preprocessing ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"1_dataset_ML_ready.csv\", index_col=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Custom helper function\n",
    "\n",
    "I have created a custom gridSearch function that is 'Fault tolerant' and which prevent the gridSearch from craching in case of incompatible arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create all tuples of parameters\n",
    "from itertools import product #Returns the cartesian product of lists (same as nested for loops)\n",
    "def all_params_grid(dico):\n",
    "    #Create list of keys and a list of values\n",
    "    keys = list(dico.keys())\n",
    "    values = dico.values()\n",
    "    #Create all possible combinations of parameters\n",
    "    params = []    \n",
    "    for value in product(*values):#Loop trough all the combination of values\n",
    "        subParam =dict() #reconstruct the dictionary of parameters\n",
    "        for i in range(len(keys)):           \n",
    "            subParam[str(keys[i])] = value[i] #Attribute the respective value to the respective key\n",
    "        params.append(subParam)\n",
    "    return(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "#Custom training method with cross validation\n",
    "def trainRawModel(strModel,params, x_train, y_train, x_test, y_test):\n",
    "    '''This function is used to train the model without any ensemble method'''    \n",
    "    #Instanciate the model\n",
    "    model = eval(strModel)()\n",
    "    #Set parameters\n",
    "    model.set_params(**params)\n",
    "    \n",
    "    #Train Base model No ensemble           \n",
    "    model_raw = model.fit(x_train,y_train)        \n",
    "    cv = cross_validate(model_raw, x_train, y_train, cv=10, scoring=['recall', 'roc_auc', 'f1'], \n",
    "                        return_train_score=False,n_jobs=-1)        \n",
    "    model_raw.fit(x_train,y_train)\n",
    "\n",
    "    #Predict model        \n",
    "    y_pred_raw = model_raw.predict(x_test)\n",
    "\n",
    "    roc_predict_raw = roc_auc_score(y_test, y_pred_raw, average='macro', sample_weight=None)\n",
    "    obj = {\n",
    "        'model_raw': model_raw,\n",
    "        'cv_raw': cv,\n",
    "        'roc_predict_raw': roc_predict_raw\n",
    "    }        \n",
    "    return(obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Gridsearch function \n",
    "def custom_gridSearch(strModel, param_dict, x_train, y_train, x_test, y_test):\n",
    "    params = All_params_grid(param_dict)\n",
    "    best_model = ''\n",
    "    \n",
    "    for param in params:  \n",
    "        try:\n",
    "            model = trainRawModel(strModel,param, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "        \n",
    "            if best_model == '':\n",
    "                best_model = model\n",
    "            elif best_model['roc_predict_raw'] < model['roc_predict_raw']:\n",
    "                best_model = model\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return best_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply adaptive boosting classifier on a already tuned model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def ada_boost(model, x_train, y_train, x_test, y_test):\n",
    "        #Try model with boosting\n",
    "        try:\n",
    "            adaGS_Param ={\n",
    "                'algorithm':['SAMME'],\n",
    "                'base_estimator':[model['model_raw']],\n",
    "                'n_estimators':[50, 80,100,500]            \n",
    "            }\n",
    "            adaBoost = AdaBoostClassifier()\n",
    "\n",
    "            adaBGS = GridSearchCV(adaBoost, adaGS_Param, cv=10, error_score=-1, scoring='roc_auc')\n",
    "            #Training a model\n",
    "            adaBGS.fit(x_train,y_train)        \n",
    "        \n",
    "            adaBest = adaBGS.best_estimator_\n",
    "            \n",
    "            y_pred_adaB = adaBGS.best_estimator_.predict(X_test)\n",
    "            \n",
    "            adaScore =  roc_auc_score(y_test, y_pred_adaB, average='macro', sample_weight=None)\n",
    "            \n",
    "        #Return final object\n",
    "        except:\n",
    "            adaBest=None\n",
    "            adaScore=0\n",
    "            \n",
    "        #bagging\n",
    "                               \n",
    "        obj = {\n",
    "            'initial_model' : model,\n",
    "            'model_adaBoost': adaBest,\n",
    "            'adaBoost_score':adaScore            \n",
    "        }\n",
    "        \n",
    "        return(obj)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply a bagging classifier on a already tuned model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "def baggingModel(model, x_train, y_train, x_test, y_test):   \n",
    "    \n",
    "        params = {   \n",
    "            'base_estimator':[model['model_raw']],\n",
    "            'max_features' : [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "            'max_samples' : [0.05, 0.1, 0.2, 0.5]\n",
    "        }\n",
    "        try:\n",
    "            \n",
    "            BaggingModel = BaggingClassifier()\n",
    "            GS = GridSearchCV(BaggingModel, params, cv=5, scoring='roc_auc')\n",
    "            GS.fit(x_train, y_train)\n",
    "            \n",
    "            bestBag = GS.best_estimator_\n",
    "\n",
    "            y_pred_bagging = bestBag.predict(X_test)\n",
    "\n",
    "            model_bagging_score = roc_auc_score(y_test,y_pred_bagging, average='macro', sample_weight=None)\n",
    "            \n",
    "        except:\n",
    "            bestBag = None,\n",
    "            model_bagging_score = 0\n",
    "        \n",
    "        \n",
    "        obj ={\n",
    "            'initial_model' : model,\n",
    "            'model_bagging' : bestBag,\n",
    "            'bagging_score': model_bagging_score\n",
    "            }\n",
    "        \n",
    "        return(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the predictions\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "#Available Classifiers\n",
    "# classifiers =['DecisionTreeClassifier', \"LogisticRegression\", \"XGBClassifier\", \n",
    "#               'SVC', 'RandomForestClassifier', \"GradientBoostingClassifier\", \n",
    "#               \"PassiveAggressiveClassifier\", \"SGDClassifier\" ]\n",
    "\n",
    "def prediction_pipeline(classifiers_list, X_train_scaled, y_train, X_test_scaled, y_test):\n",
    "    #Train all models    \n",
    "    All_classifiers= defaultdict(dict)\n",
    "    compt = 1\n",
    "    for classifier in classifiers_list:\n",
    "        model = custom_gridSearch(classifier, model_parameters[classifier], X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "        All_classifiers[classifier][classifier + '_raw'] = model\n",
    "\n",
    "        #Store intermediate versions\n",
    "        pickling_on = open(\"zz_model_{}_out_of_{}.pickle\".format(compt, len(classifiers)),\"wb\")\n",
    "        pickle.dump(All_classifiers, pickling_on)\n",
    "        pickling_on.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a sample for testing the code\n",
    "import random\n",
    "indecies = random.sample(range(len(data)), 500)\n",
    "data = data.iloc[indecies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('readmitted', axis=1)\n",
    "Y = data['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a dictionary of model parameters\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_parameters = {\n",
    "    'DecisionTreeClassifier':{    \n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth':[None], #integer\n",
    "        'min_samples_split': [2, 4, 8, 20], #integer or proportion of samples\n",
    "        'min_samples_leaf':[1, 5, 10 , 20],\n",
    "        'max_features':['auto', 'log2', None],\n",
    "        'max_leaf_nodes' :[None], #int\n",
    "        'min_impurity_decrease' :[1e-7],    \n",
    "        'class_weight':['balanced'],    \n",
    "    },\n",
    "    #-------------\n",
    "    \"LogisticRegression\":{\n",
    "        'penalty':['l2','l1'], # The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties\n",
    "        'dual':[False], #Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features.\n",
    "        'tol':[0.0001], #Tolerance for stopping criteria\n",
    "        'C':[1.0], #Like in support vector machines, smaller values specify stronger regularization.\n",
    "        'fit_intercept':[True], \n",
    "        'intercept_scaling':[1], \n",
    "        'class_weight':['balanced'], \n",
    "        'random_state':[101], \n",
    "        'solver':['liblinear', #Good choice for small datasets, one-vs-rest only, handels L1\n",
    "                  'newton-cg',  #multinomial problems (multi-class), L2\n",
    "                  'lbfgs',  #multinomial problems (multi-class), L2\n",
    "                  'sag', #Stochastic Average Gradient descent #Good choice for small datasets, multinomial problems, L2\n",
    "                  'saga', #Good choice for small datasets, multinomial problems, handels L1\n",
    "                 ], \n",
    "        'max_iter':[100, 500], #Useful only for the newton-cg, sag and lbfgs solvers\n",
    "        'multi_class':['ovr', \n",
    "                       'multinomial', \n",
    "                       'auto'], #‘ovr’, ‘multinomial’, ‘auto’\n",
    "        'verbose':[0], \n",
    "        'warm_start':[False], \n",
    "        'n_jobs':[-1]\n",
    "    },\n",
    "    #-------------\n",
    "    'SVC':{\n",
    "        'C':[0.5, 1.0, 2, 5], \n",
    "        'kernel':['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "        'degree':[3,4,5], #degree of the polynomial (only for polynomial kernel)\n",
    "        'gamma': ['auto', 'scale'],\n",
    "        'coef0': [0.0, 1, 2], \n",
    "        'shrinking':[True], \n",
    "        'probability':[False],  #Change this to True if probabilities need to be calculated\n",
    "        'tol': [0.001], \n",
    "        'cache_size':[200], \n",
    "        'class_weight':['balanced'], \n",
    "        'verbose':[False], \n",
    "        'max_iter':[-1], \n",
    "        'decision_function_shape':['ovr', 'ovo'], \n",
    "        'random_state': [101]    \n",
    "    },\n",
    "    #-------------\n",
    "    'RandomForestClassifier':{\n",
    "        'n_estimators':[100, 200, 1000],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth':[None], #integer\n",
    "        'min_samples_split': [2, 8, 20], #integer or proportion of samples\n",
    "        'min_samples_leaf':[1, 5, 10, 20],\n",
    "        'max_features':['auto', 'log2', None],\n",
    "        'max_leaf_nodes' :[None], #int\n",
    "        'min_impurity_decrease' :[1e-7],    \n",
    "        'class_weight':['balanced', 'balanced_subsample'],    \n",
    "        'bootstrap':[True],\n",
    "        'n_jobs':[-1]\n",
    "    },\n",
    "    #-------------\n",
    "    \"GradientBoostingClassifier\": {\n",
    "        'loss':['deviance'], \n",
    "        'learning_rate':[0.1], \n",
    "        'n_estimators':[100, 200, 1000], \n",
    "        'subsample':[1.0], \n",
    "        'criterion': ['friedman_mse'], \n",
    "        'min_samples_split':[2, 5, 10, 20], \n",
    "        'min_samples_leaf': [2, 5, 10, 20], \n",
    "        'min_weight_fraction_leaf':[0.0], \n",
    "        'max_depth':[3, 4, 5, 10], \n",
    "        'min_impurity_decrease': [0.0], \n",
    "        'min_impurity_split': [None], \n",
    "        'init': [None], \n",
    "        'random_state':[101], \n",
    "        'max_features':[None, 'sqrt', 'log2'], \n",
    "        'verbose':[0], \n",
    "        'max_leaf_nodes':[None], \n",
    "        'warm_start':[False], \n",
    "        'presort':['auto'], \n",
    "        'validation_fraction': [0.1], \n",
    "        'n_iter_no_change':[5], #if the score is not improving for 3 iterations ==>Early stopping. Default None\n",
    "        'tol':[0.0001]\n",
    "    },\n",
    "    #-------------------------------\n",
    "    \"SGDClassifier\":{\n",
    "        'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'], \n",
    "        'penalty':['l2', 'l1', 'elasticnet'], \n",
    "        'alpha': [0.0001], \n",
    "        'l1_ratio': [0.15, 0.4], \n",
    "        'fit_intercept':[True], \n",
    "        'max_iter':[1000], \n",
    "        'tol': [0.001], \n",
    "        'shuffle':[True], \n",
    "        'verbose':[0], \n",
    "        'epsilon':[0.1],        \n",
    "        'random_state':[101], \n",
    "        'learning_rate':['optimal', 'adaptive', 'invscaling', 'constant'], \n",
    "        'eta0':[0.0], \n",
    "        'power_t':[0.5], \n",
    "        'early_stopping':[True], \n",
    "        'validation_fraction':[0.1], \n",
    "        'n_iter_no_change': [10], \n",
    "        'class_weight':['balanced'], \n",
    "        'warm_start':[False], \n",
    "        'average':[False],\n",
    "        'n_jobs':[-1]\n",
    "    },\n",
    "    #-------------------------------    \n",
    "    \"PassiveAggressiveClassifier\": {\n",
    "        'C':[1.0], \n",
    "        'fit_intercept':[True], \n",
    "        'max_iter':[1000], \n",
    "        'tol': [0.001], \n",
    "        'early_stopping':[True], \n",
    "        'validation_fraction':[0.1], \n",
    "        'n_iter_no_change': [10], \n",
    "        'shuffle':[True], \n",
    "        'verbose':[0], \n",
    "        'loss':['hinge', 'squared_hinge'], \n",
    "        'n_jobs':[-1], \n",
    "        'random_state':[101], \n",
    "        'warm_start':[False], \n",
    "        'class_weight':['balanced'], \n",
    "        'average':[False]\n",
    "    },\n",
    "    #-------------------------------    \n",
    "    \"XGBClassifier\": {\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.1],\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'verbosity':[0],\n",
    "        'silent': [None],\n",
    "        \"objective\": ['binary:logistic'],\n",
    "        'booster': ['gbtree'],\n",
    "        'nthread': [None],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],        \n",
    "        'min_child_weight': [1, 5, 10],        \n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'colsample_bylevel': [1],\n",
    "        'colsample_bynode': [1],\n",
    "        'reg_alpha': [1],\n",
    "        'reg_lambda': [1],\n",
    "        'scale_pos_weight': [1],\n",
    "        'base_score': [0.5],\n",
    "        'random_state': [101],\n",
    "        'seed': [None],\n",
    "        'missing': [None],        \n",
    "        'n_jobs':[-1]                   \n",
    "    }    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Scikit-learn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Available Classifiers\n",
    "#classifiers =['DecisionTreeClassifier', \"LogisticRegression\", \"XGBClassifier\", 'SVC', 'RandomForestClassifier', \"GradientBoostingClassifier\", \"PassiveAggressiveClassifier\", \"SGDClassifier\", ]\n",
    "\n",
    "classifiers =[\"XGBClassifier\", \\\n",
    "              'DecisionTreeClassifier', \"LogisticRegression\",'SVC',\\\n",
    "              'RandomForestClassifier', \"GradientBoostingClassifier\", \\\n",
    "              \"PassiveAggressiveClassifier\", \"SGDClassifier\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking Class\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product #Returns the cartesian product of lists (same as nested for loops)\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Implementing a stacking class\n",
    "class Stacking():\n",
    "#     x_train = \"\"\n",
    "#     y_test = \"\" \n",
    "    \n",
    "    _x_train_scaled_fold1 = \"\"\n",
    "    _y_test_fold1 = \"\"\n",
    "    _x_train_scaled_fold2 = \"\"\n",
    "    _y_test_fold2 = \"\"\n",
    "    _scaler = \"\"\n",
    "    #Fitting the base models to the 1st fold of training and getting prediction on the second fold\n",
    "    _trainin_f1_models = {}\n",
    "    _training_set_meta_classifier = {} #this will be based on prediction on the second fold using models fro the first fold\n",
    "    _trainin_f2_models = {}\n",
    "    \n",
    "    _testing_set_meta_classifier = {} # This will contain de predictions to be fed to the f2 models from the testing set\n",
    "    _final_results_testing = defaultdict(dict)\n",
    "       \n",
    "    def __init__(self, param_dict, classifiers,  x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.classifiers = classifiers\n",
    "        self.param_dict = param_dict\n",
    "        \n",
    "    def _split_and_scale(self): \n",
    "        X_train_f1, X_train_f2, y_train_f1, y_train_f2 = train_test_split(self.x_train, self.y_train, \n",
    "                                                                          test_size=0.5, random_state=101)\n",
    "        \n",
    "        Scaler = StandardScaler()\n",
    "        self._x_train_scaled_fold1 = Scaler.fit_transform(X_train_f1)\n",
    "        self._x_train_scaled_fold2 = Scaler.transform(X_train_f2)\n",
    "        \n",
    "        self._y_test_fold1 = y_train_f1\n",
    "        self._y_test_fold2 = y_train_f2\n",
    "        self._scaler = Scaler\n",
    "        \n",
    "    def _all_params_grid(self, dict_params):\n",
    "        '''Generate all the combinations aof parameters from a dictionary'''\n",
    "        # Create list of keys and a list of values\n",
    "        keys = list(dict_params.keys())\n",
    "        values = dict_params.values()\n",
    "        # Create all possible combinations of parameters\n",
    "        params = []    \n",
    "        for value in product(*values):#Loop trough all the combination of values\n",
    "            subParam =dict() #reconstruct the dictionary of parameters\n",
    "            for i in range(len(keys)):           \n",
    "                subParam[str(keys[i])] = value[i] #Attribute the respective value to the respective key\n",
    "            params.append(subParam)\n",
    "        return(params)\n",
    "    \n",
    "    def _train_raw_model_stacking(self, strModel, params, x_train, y_train):\n",
    "        '''This function is used to train the model without any ensemble method'''    \n",
    "        #Instanciate the model\n",
    "        model = eval(strModel)()\n",
    "        #Set parameters\n",
    "        model.set_params(**params)\n",
    "\n",
    "        #Train Base model No ensemble           \n",
    "        model_raw = model.fit(x_train,y_train)        \n",
    "        cv = cross_validate(model_raw, x_train, y_train, cv=10, scoring=['recall', 'roc_auc', 'f1'], \n",
    "                            return_train_score=False,n_jobs=-1)     \n",
    "\n",
    "        model_raw.fit(x_train,y_train)    \n",
    "        obj = {\n",
    "            'model_raw': model_raw,\n",
    "            'cv_raw': cv        \n",
    "        }        \n",
    "        return(obj) \n",
    "    \n",
    "    def _custom_gridSearch_stacking(self, strModel, param_dict, x_train, y_train):\n",
    "        params = self._all_params_grid(param_dict)\n",
    "        best_model = ''\n",
    "\n",
    "        for param in params:  \n",
    "            try:\n",
    "                model = self._train_raw_model_stacking(strModel,param, x_train, y_train)       \n",
    "\n",
    "                if best_model == '':\n",
    "                    best_model = model\n",
    "                elif best_model['cv_raw']['test_roc_auc'].mean() < model['cv_raw']['test_roc_auc'].mean():\n",
    "                    best_model = model\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return best_model \n",
    "    \n",
    "    \n",
    "    def train_fold1(self):\n",
    "        compt = 1\n",
    "        for classifier in self.classifiers:\n",
    "            try:\n",
    "                print('training training fold 1: ' + classifier)\n",
    "                model = self._custom_gridSearch_stacking(classifier, self.param_dict[classifier], \n",
    "                                                   self._x_train_scaled_fold1 , self._y_test_fold1)\n",
    "                \n",
    "                pickling_on = open(\"Xgb.pickle\",\"wb\")\n",
    "                pickle.dump(model, pickling_on)\n",
    "                pickling_on.close()\n",
    "                \n",
    "                self._trainin_f1_models[classifier] = model\n",
    "                self._training_set_meta_classifier[classifier]= model['model_raw'].predict(self._x_train_scaled_fold2)\n",
    "\n",
    "                compt += 1\n",
    "            except:\n",
    "                print ('error f1 with: ' + classifier)\n",
    "                \n",
    "    def train_fold2(self):            \n",
    "        dataset = pd.DataFrame(self._training_set_meta_classifier)\n",
    "        \n",
    "        #making sure that the order of the columns stays the same\n",
    "        dataset = dataset[self.classifiers] \n",
    "\n",
    "        for classifier in self.classifiers:\n",
    "            try:\n",
    "                print('training training fold 2: ' + classifier)\n",
    "                model = self._custom_gridSearch_stacking(classifier, self.param_dict[classifier], \n",
    "                                                   dataset , self._y_test_fold2)   \n",
    "                \n",
    "                self._trainin_f2_models[classifier] = model \n",
    "            \n",
    "            except: \n",
    "                print ('error f2 with: ' + classifier)\n",
    "\n",
    "\n",
    "    def predict(self, x_test, y_test):\n",
    "        #Scale the testing set\n",
    "        scaled_test = self._scaler.transform(x_test, y_test)\n",
    "        \n",
    "        # Get the predictions for building the f1 dataset\n",
    "        for model1 in self._trainin_f1_models:\n",
    "            self._testing_set_meta_classifier[model1] = self._trainin_f1_models[model1]['model_raw'].predict(scaled_test)\n",
    "            \n",
    "        dataset = pd.DataFrame(self._testing_set_meta_classifier)\n",
    "        \n",
    "        #making sure that the order of the columns stays the same\n",
    "        dataset = dataset[self.classifiers]\n",
    "        \n",
    "        for model2 in self._trainin_f2_models:\n",
    "            pred = self._trainin_f2_models[model2]['model_raw'].predict(dataset)\n",
    "            \n",
    "            self._final_results_testing[model2]['roc_auc_score'] = roc_auc_score(y_test, pred)\n",
    "            self._final_results_testing[model2]['classification_report'] = classification_report(y_test, pred)\n",
    "    \n",
    "\n",
    "        return(self._final_results_testing)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "s = Stacking(model_parameters, classifiers, X_train, y_train)\n",
    "s._split_and_scale()\n",
    "s.train_fold1()\n",
    "s.train_fold2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imedya\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\imedya\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\imedya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "s.predict(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remain to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a voting classifier on the models trained in f2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
