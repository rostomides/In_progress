{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create all tuples of parameters\n",
    "from itertools import product #Returns the cartesian product of lists (same as nested for loops)\n",
    "def All_params_grid(dico):\n",
    "    #Create list of keys and a list of values\n",
    "    keys = list(dico.keys())\n",
    "    values = dico.values()\n",
    "    #Create all possible combinations of parameters\n",
    "    params = []    \n",
    "    for value in product(*values):#Loop trough all the combination of values\n",
    "        subParam =dict() #reconstruct the dictionary of parameters\n",
    "        for i in range(len(keys)):           \n",
    "            subParam[str(keys[i])] = value[i] #Attribute the respective value to the respective key\n",
    "        params.append(subParam)\n",
    "    return(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "#Custom training method with cross validation\n",
    "def trainRawModel(strModel,params, x_train, y_train, x_test, y_test):\n",
    "    '''This function is used to train the model without any ensemble method'''    \n",
    "    #Instanciate the model\n",
    "    model = eval(strModel)()\n",
    "    #Set parameters\n",
    "    model.set_params(**params)\n",
    "    \n",
    "    #Train Base model No ensemble           \n",
    "    model_raw = model.fit(x_train,y_train)        \n",
    "    cv = cross_validate(model_raw, x_train, y_train, cv=5, scoring=['recall', 'roc_auc', 'f1'], \n",
    "                        return_train_score=False,n_jobs=5)        \n",
    "    model_raw.fit(x_train,y_train)\n",
    "\n",
    "    #Predict model        \n",
    "    y_pred_raw = model_raw.predict(x_test)\n",
    "\n",
    "    roc_predict_raw = roc_auc_score(y_test, y_pred_raw, average='macro', sample_weight=None)\n",
    "    obj = {\n",
    "        'model_raw': model_raw,\n",
    "        'cv_raw': cv,\n",
    "        'roc_predict_raw': roc_predict_raw\n",
    "    }        \n",
    "    return(obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from random import seed\n",
    "seed(12345678)\n",
    "\n",
    "# Custom Gridsearch function \n",
    "def custom_gridSearch(strModel, param_dict, x_train, y_train, x_test, y_test):\n",
    "    params = All_params_grid(param_dict)\n",
    "    \n",
    "    params = shuffle(params)\n",
    "    \n",
    "    best_model = ''\n",
    "    counter  = 0\n",
    "    print('testing param list : 1/' + str(len(params)))\n",
    "    for param in params:  \n",
    "        \n",
    "        pickling_on = open(\"Xgboost_last_set_of_paraneters.pickle\" ,\"wb\")\n",
    "        pickle.dump(param , pickling_on)\n",
    "        pickling_on.close()\n",
    "        \n",
    "        counter += 1\n",
    "        if counter%10 == 0:\n",
    "            print('testing param list : {}/{} \\t  Best auc : {}'.format(str(counter), \n",
    "                                                                        str(len(params)), \n",
    "                                                                        str(best_model['roc_predict_raw']) \n",
    "                                                                       ))\n",
    "            \n",
    "                   \n",
    "            \n",
    "        try:\n",
    "            model = trainRawModel(strModel,param, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "            if best_model == '':\n",
    "                best_model = model\n",
    "                \n",
    "                pickling_on = open(\"Xgboost_best_model_{}.pickle\".format(str(counter)) ,\"wb\")\n",
    "                pickle.dump(best_model, pickling_on)\n",
    "                pickling_on.close()\n",
    "                \n",
    "            elif best_model['roc_predict_raw'] < model['roc_predict_raw']:\n",
    "                best_model = model\n",
    "                \n",
    "                pickling_on = open(\"Xgboost_best_model_{}.pickle\".format(str(counter)) ,\"wb\")\n",
    "                pickle.dump(best_model, pickling_on)\n",
    "                pickling_on.close()  \n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "    return best_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the predictions\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "#Available Classifiers\n",
    "# classifiers =['DecisionTreeClassifier', \"LogisticRegression\", \"XGBClassifier\", \n",
    "#               'SVC', 'RandomForestClassifier', \"GradientBoostingClassifier\", \n",
    "#               \"PassiveAggressiveClassifier\", \"SGDClassifier\" ]\n",
    "\n",
    "def prediction_pipeline(classifiers_list, X_train_scaled, y_train, X_test_scaled, y_test):\n",
    "    #Train all models    \n",
    "    All_classifiers= defaultdict(dict)\n",
    "    compt = 1\n",
    "    for classifier in classifiers_list:\n",
    "        print('Current classifier ' + classifier)\n",
    "               \n",
    "        try:\n",
    "            model = custom_gridSearch(classifier, model_parameters[classifier], X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "            All_classifiers[classifier][classifier + '_raw'] = model\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model_parameters = {\n",
    "\"XGBClassifier\": {\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.1],\n",
    "        'n_estimators': [100, 500, 700],\n",
    "        'verbosity':[0],\n",
    "        'silent': [None],\n",
    "        \"objective\": ['binary:logistic'],\n",
    "        'booster': ['gbtree'],\n",
    "        'nthread': [None],\n",
    "        'gamma': [0],        \n",
    "         'min_child_weight': [1, 5, 10],        \n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'colsample_bylevel': [1],\n",
    "        'colsample_bynode': [1],\n",
    "        'reg_alpha': [0, 1, 2 , 6],\n",
    "        'reg_lambda': [1, 2, 3, 6],\n",
    "        'scale_pos_weight': [1],\n",
    "        'base_score': [0.5],\n",
    "        'random_state': [101],\n",
    "        'seed': [None],\n",
    "        'missing': [None], \n",
    "#         'tree_method':['gpu_hist'], #  default 'auto', 'gpu_exact'\n",
    "        'updater':['grow_gpu']   \n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "data = pd.read_csv(\"1_dataset_ML_no_OHE_ready.csv\", index_col=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"readmitted\", axis=1)\n",
    "Y = data[\"readmitted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['race', 'gender', 'age', 'admission_type_id',\n",
    "       'discharge_disposition_id', 'admission_source_id', 'diag_1', 'diag_2',\n",
    "       'diag_3', 'metformin', 'repaglinide', 'glimepiride', 'glipizide',\n",
    "       'glyburide', 'pioglitazone', 'rosiglitazone', 'insulin', 'change',\n",
    "       'diabetesMed']\n",
    "\n",
    "continuous_columns = [col for col in X.columns if col not in cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use label encoder on the categorical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "le = defaultdict(LabelEncoder)\n",
    "fit = X[cat_columns].apply(lambda x: le[x.name].fit_transform(x))\n",
    "#fit.apply(lambda x: le[x.name].inverse_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruct the dataset\n",
    "dataset = pd.concat( [fit, X[continuous_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(dataset, Y, test_size=0.1, random_state=101)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current classifier XGBClassifier\n",
      "testing param list : 1/6480\n",
      "testing param list : 2/6480\n",
      "Best auc : 0.631316416902169\n",
      "testing param list : 4/6480\n",
      "Best auc : 0.6314886060040901\n",
      "testing param list : 6/6480\n",
      "Best auc : 0.6317978962279184\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action=\"once\")\n",
    "\n",
    "#Available Classifiers\n",
    "#classifiers =['DecisionTreeClassifier', \"LogisticRegression\", \"XGBClassifier\", 'SVC', 'RandomForestClassifier', \"GradientBoostingClassifier\", \"PassiveAggressiveClassifier\", \"SGDClassifier\", ]\n",
    "\n",
    "classifiers =[\"XGBClassifier\"]\n",
    "\n",
    "#running the prediction pipeline\n",
    "prediction_pipeline(classifiers, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
