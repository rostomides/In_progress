{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 10} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor Flow Version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Larbi\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Larbi\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 1s - loss: 597369.7458\n",
      "Epoch 2/100\n",
      " - 0s - loss: 42331.4554\n",
      "Epoch 3/100\n",
      " - 0s - loss: 8345.2515\n",
      "Epoch 4/100\n",
      " - 0s - loss: 6770.5373\n",
      "Epoch 5/100\n",
      " - 0s - loss: 323.3547\n",
      "Epoch 6/100\n",
      " - 0s - loss: 556.7790\n",
      "Epoch 7/100\n",
      " - 0s - loss: 107.3566\n",
      "Epoch 8/100\n",
      " - 0s - loss: 109.6168\n",
      "Epoch 9/100\n",
      " - 0s - loss: 78.9051\n",
      "Epoch 10/100\n",
      " - 0s - loss: 78.8592\n",
      "Epoch 11/100\n",
      " - 0s - loss: 76.1935\n",
      "Epoch 12/100\n",
      " - 0s - loss: 76.7220\n",
      "Epoch 13/100\n",
      " - 0s - loss: 76.2721\n",
      "Epoch 14/100\n",
      " - 0s - loss: 76.6083\n",
      "Epoch 15/100\n",
      " - 0s - loss: 75.9515\n",
      "Epoch 16/100\n",
      " - 0s - loss: 76.1172\n",
      "Epoch 17/100\n",
      " - 0s - loss: 76.7687\n",
      "Epoch 18/100\n",
      " - 0s - loss: 75.9118\n",
      "Epoch 19/100\n",
      " - 0s - loss: 75.9420\n",
      "Epoch 20/100\n",
      " - 0s - loss: 75.6152\n",
      "Epoch 21/100\n",
      " - 0s - loss: 75.4861\n",
      "Epoch 22/100\n",
      " - 0s - loss: 75.1874\n",
      "Epoch 23/100\n",
      " - 0s - loss: 75.7379\n",
      "Epoch 24/100\n",
      " - 0s - loss: 74.8318\n",
      "Epoch 25/100\n",
      " - 0s - loss: 74.8621\n",
      "Epoch 26/100\n",
      " - 0s - loss: 74.6038\n",
      "Epoch 27/100\n",
      " - 0s - loss: 74.5605\n",
      "Epoch 28/100\n",
      " - 0s - loss: 74.3867\n",
      "Epoch 29/100\n",
      " - 0s - loss: 75.1863\n",
      "Epoch 30/100\n",
      " - 0s - loss: 75.1371\n",
      "Epoch 31/100\n",
      " - 0s - loss: 74.8725\n",
      "Epoch 32/100\n",
      " - 0s - loss: 73.7870\n",
      "Epoch 33/100\n",
      " - 0s - loss: 73.6282\n",
      "Epoch 34/100\n",
      " - 0s - loss: 74.1379\n",
      "Epoch 35/100\n",
      " - 0s - loss: 73.5478\n",
      "Epoch 36/100\n",
      " - 0s - loss: 73.1868\n",
      "Epoch 37/100\n",
      " - 0s - loss: 73.4747\n",
      "Epoch 38/100\n",
      " - 0s - loss: 72.8881\n",
      "Epoch 39/100\n",
      " - 0s - loss: 72.6884\n",
      "Epoch 40/100\n",
      " - 0s - loss: 72.8963\n",
      "Epoch 41/100\n",
      " - 0s - loss: 72.8220\n",
      "Epoch 42/100\n",
      " - 0s - loss: 72.2877\n",
      "Epoch 43/100\n",
      " - 0s - loss: 72.5699\n",
      "Epoch 44/100\n",
      " - 0s - loss: 72.5148\n",
      "Epoch 45/100\n",
      " - 0s - loss: 71.5175\n",
      "Epoch 46/100\n",
      " - 0s - loss: 71.1662\n",
      "Epoch 47/100\n",
      " - 0s - loss: 71.7443\n",
      "Epoch 48/100\n",
      " - 0s - loss: 70.8469\n",
      "Epoch 49/100\n",
      " - 0s - loss: 70.8942\n",
      "Epoch 50/100\n",
      " - 0s - loss: 70.7588\n",
      "Epoch 51/100\n",
      " - 0s - loss: 70.6516\n",
      "Epoch 52/100\n",
      " - 0s - loss: 70.7297\n",
      "Epoch 53/100\n",
      " - 0s - loss: 69.8209\n",
      "Epoch 54/100\n",
      " - 0s - loss: 70.1679\n",
      "Epoch 55/100\n",
      " - 0s - loss: 69.9080\n",
      "Epoch 56/100\n",
      " - 0s - loss: 69.6080\n",
      "Epoch 57/100\n",
      " - 0s - loss: 69.4989\n",
      "Epoch 58/100\n",
      " - 0s - loss: 69.0164\n",
      "Epoch 59/100\n",
      " - 0s - loss: 69.0314\n",
      "Epoch 60/100\n",
      " - 0s - loss: 68.5209\n",
      "Epoch 61/100\n",
      " - 0s - loss: 69.3827\n",
      "Epoch 62/100\n",
      " - 0s - loss: 69.1155\n",
      "Epoch 63/100\n",
      " - 0s - loss: 68.4994\n",
      "Epoch 64/100\n",
      " - 0s - loss: 69.2898\n",
      "Epoch 65/100\n",
      " - 0s - loss: 67.7111\n",
      "Epoch 66/100\n",
      " - 0s - loss: 67.1723\n",
      "Epoch 67/100\n",
      " - 0s - loss: 67.1624\n",
      "Epoch 68/100\n",
      " - 0s - loss: 66.4156\n",
      "Epoch 69/100\n",
      " - 0s - loss: 66.5964\n",
      "Epoch 70/100\n",
      " - 0s - loss: 66.1075\n",
      "Epoch 71/100\n",
      " - 0s - loss: 66.2504\n",
      "Epoch 72/100\n",
      " - 0s - loss: 65.6385\n",
      "Epoch 73/100\n",
      " - 0s - loss: 66.9600\n",
      "Epoch 74/100\n",
      " - 0s - loss: 68.2136\n",
      "Epoch 75/100\n",
      " - 0s - loss: 66.1392\n",
      "Epoch 76/100\n",
      " - 0s - loss: 65.1053\n",
      "Epoch 77/100\n",
      " - 0s - loss: 64.7433\n",
      "Epoch 78/100\n",
      " - 0s - loss: 67.7205\n",
      "Epoch 79/100\n",
      " - 0s - loss: 64.2454\n",
      "Epoch 80/100\n",
      " - 0s - loss: 64.7655\n",
      "Epoch 81/100\n",
      " - 0s - loss: 65.4154\n",
      "Epoch 82/100\n",
      " - 0s - loss: 63.7515\n",
      "Epoch 83/100\n",
      " - 0s - loss: 62.8307\n",
      "Epoch 84/100\n",
      " - 0s - loss: 63.6302\n",
      "Epoch 85/100\n",
      " - 0s - loss: 63.3037\n",
      "Epoch 86/100\n",
      " - 0s - loss: 63.2667\n",
      "Epoch 87/100\n",
      " - 0s - loss: 63.2995\n",
      "Epoch 88/100\n",
      " - 0s - loss: 61.8026\n",
      "Epoch 89/100\n",
      " - 0s - loss: 61.2550\n",
      "Epoch 90/100\n",
      " - 0s - loss: 60.9245\n",
      "Epoch 91/100\n",
      " - 0s - loss: 60.7117\n",
      "Epoch 92/100\n",
      " - 0s - loss: 60.2140\n",
      "Epoch 93/100\n",
      " - 0s - loss: 61.6069\n",
      "Epoch 94/100\n",
      " - 0s - loss: 60.8121\n",
      "Epoch 95/100\n",
      " - 0s - loss: 61.1875\n",
      "Epoch 96/100\n",
      " - 0s - loss: 60.1582\n",
      "Epoch 97/100\n",
      " - 0s - loss: 59.1764\n",
      "Epoch 98/100\n",
      " - 0s - loss: 59.1730\n",
      "Epoch 99/100\n",
      " - 0s - loss: 59.5302\n",
      "Epoch 100/100\n",
      " - 0s - loss: 58.6355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x247e382aeb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "cars = df['name']\n",
    "\n",
    "# Handle missing value\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "\n",
    "# Pandas to Numpy\n",
    "x = df[['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "       'acceleration', 'year', 'origin']].values\n",
    "y = df['mpg'].values # regression\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, #Number of neurons in the first layer\n",
    "                input_dim=x.shape[1], # Number of columns in the dataset (or size of picture, this parameter takes all the dimensions but the dimension that corresponds to the number of samples)\n",
    "                activation='relu')) # Hidden 1\n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(1)) # One neuron because we are dealing with regression problem\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x,y,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (398, 1)\n",
      "[[12.482341 ]\n",
      " [15.832072 ]\n",
      " [15.729106 ]\n",
      " [17.892956 ]\n",
      " [15.757701 ]\n",
      " [15.2847395]\n",
      " [17.22462  ]\n",
      " [17.973217 ]\n",
      " [18.678234 ]\n",
      " [17.033886 ]\n",
      " [10.410533 ]\n",
      " [15.9375105]\n",
      " [ 4.3167524]\n",
      " [-3.8693132]\n",
      " [31.822826 ]\n",
      " [18.500652 ]\n",
      " [18.567242 ]\n",
      " [14.239604 ]\n",
      " [31.341015 ]\n",
      " [18.020336 ]\n",
      " [31.27287  ]\n",
      " [31.52592  ]\n",
      " [32.835217 ]\n",
      " [34.501324 ]\n",
      " [16.1067   ]\n",
      " [31.989574 ]\n",
      " [35.24708  ]\n",
      " [36.262524 ]\n",
      " [35.447765 ]\n",
      " [31.564007 ]\n",
      " [25.25288  ]\n",
      " [31.380932 ]\n",
      " [31.565365 ]\n",
      " [13.742106 ]\n",
      " [20.128185 ]\n",
      " [14.223918 ]\n",
      " [10.910991 ]\n",
      " [16.907757 ]\n",
      " [18.658398 ]\n",
      " [14.606029 ]\n",
      " [14.934215 ]\n",
      " [19.184399 ]\n",
      " [21.172619 ]\n",
      " [14.689647 ]\n",
      " [18.027294 ]\n",
      " [13.849925 ]\n",
      " [20.976635 ]\n",
      " [14.019267 ]\n",
      " [10.148875 ]\n",
      " [26.97044  ]\n",
      " [28.767986 ]\n",
      " [28.780468 ]\n",
      " [29.232769 ]\n",
      " [27.510998 ]\n",
      " [27.66183  ]\n",
      " [22.049587 ]\n",
      " [25.900463 ]\n",
      " [31.752483 ]\n",
      " [28.849194 ]\n",
      " [22.511272 ]\n",
      " [25.926281 ]\n",
      " [27.04533  ]\n",
      " [19.213757 ]\n",
      " [14.389537 ]\n",
      " [19.571362 ]\n",
      " [15.065074 ]\n",
      " [19.597118 ]\n",
      " [19.798412 ]\n",
      " [17.626781 ]\n",
      " [18.714245 ]\n",
      " [18.51173  ]\n",
      " [40.322155 ]\n",
      " [20.650677 ]\n",
      " [15.82307  ]\n",
      " [20.13197  ]\n",
      " [19.238842 ]\n",
      " [38.114544 ]\n",
      " [26.181438 ]\n",
      " [31.538525 ]\n",
      " [26.701519 ]\n",
      " [27.945415 ]\n",
      " [33.474712 ]\n",
      " [32.39384  ]\n",
      " [29.106121 ]\n",
      " [31.490765 ]\n",
      " [21.121319 ]\n",
      " [19.820171 ]\n",
      " [12.611278 ]\n",
      " [18.379833 ]\n",
      " [18.034985 ]\n",
      " [18.971203 ]\n",
      " [ 8.402415 ]\n",
      " [17.80769  ]\n",
      " [20.244396 ]\n",
      " [20.626904 ]\n",
      " [21.965893 ]\n",
      " [18.230083 ]\n",
      " [18.87672  ]\n",
      " [14.230662 ]\n",
      " [15.564128 ]\n",
      " [ 9.848704 ]\n",
      " [19.497173 ]\n",
      " [19.241955 ]\n",
      " [10.984996 ]\n",
      " [15.124705 ]\n",
      " [21.023937 ]\n",
      " [24.520397 ]\n",
      " [14.837901 ]\n",
      " [32.45045  ]\n",
      " [21.3513   ]\n",
      " [32.95988  ]\n",
      " [37.63975  ]\n",
      " [27.290417 ]\n",
      " [27.518353 ]\n",
      " [32.726727 ]\n",
      " [13.092113 ]\n",
      " [28.795849 ]\n",
      " [24.380337 ]\n",
      " [25.317272 ]\n",
      " [32.147625 ]\n",
      " [37.933697 ]\n",
      " [16.209301 ]\n",
      " [36.448162 ]\n",
      " [33.616863 ]\n",
      " [20.357586 ]\n",
      " [20.697063 ]\n",
      " [18.782146 ]\n",
      " [15.562297 ]\n",
      " [14.821757 ]\n",
      " [28.32861  ]\n",
      " [27.05476  ]\n",
      " [28.359478 ]\n",
      " [23.267864 ]\n",
      " [17.097332 ]\n",
      " [17.62373  ]\n",
      " [21.615795 ]\n",
      " [19.938427 ]\n",
      " [17.685986 ]\n",
      " [21.664135 ]\n",
      " [22.33717  ]\n",
      " [22.748669 ]\n",
      " [30.790936 ]\n",
      " [28.374538 ]\n",
      " [30.186138 ]\n",
      " [23.481777 ]\n",
      " [26.369152 ]\n",
      " [29.35188  ]\n",
      " [29.464367 ]\n",
      " [26.097668 ]\n",
      " [32.71739  ]\n",
      " [33.05122  ]\n",
      " [28.527966 ]\n",
      " [17.444103 ]\n",
      " [17.068157 ]\n",
      " [ 7.841777 ]\n",
      " [ 6.5477705]\n",
      " [15.219005 ]\n",
      " [15.297557 ]\n",
      " [22.025402 ]\n",
      " [17.076061 ]\n",
      " [23.378857 ]\n",
      " [19.129406 ]\n",
      " [18.276379 ]\n",
      " [19.89381  ]\n",
      " [19.36906  ]\n",
      " [13.985759 ]\n",
      " [12.423839 ]\n",
      " [29.119427 ]\n",
      " [26.103619 ]\n",
      " [15.851787 ]\n",
      " [24.433178 ]\n",
      " [31.621899 ]\n",
      " [29.145702 ]\n",
      " [33.24452  ]\n",
      " [25.329388 ]\n",
      " [27.597393 ]\n",
      " [14.653361 ]\n",
      " [33.992565 ]\n",
      " [32.538677 ]\n",
      " [35.141155 ]\n",
      " [38.309185 ]\n",
      " [22.233242 ]\n",
      " [31.90855  ]\n",
      " [27.791058 ]\n",
      " [28.515392 ]\n",
      " [30.006329 ]\n",
      " [30.753796 ]\n",
      " [20.35255  ]\n",
      " [20.780712 ]\n",
      " [13.863597 ]\n",
      " [16.147106 ]\n",
      " [18.874493 ]\n",
      " [16.856548 ]\n",
      " [16.579021 ]\n",
      " [14.189372 ]\n",
      " [23.50578  ]\n",
      " [24.199352 ]\n",
      " [27.806103 ]\n",
      " [22.463512 ]\n",
      " [20.847607 ]\n",
      " [10.378398 ]\n",
      " [19.551067 ]\n",
      " [11.870585 ]\n",
      " [26.515759 ]\n",
      " [28.951565 ]\n",
      " [29.232037 ]\n",
      " [23.28123  ]\n",
      " [35.938305 ]\n",
      " [19.487896 ]\n",
      " [34.012188 ]\n",
      " [31.068157 ]\n",
      " [36.508648 ]\n",
      " [24.609814 ]\n",
      " [13.694835 ]\n",
      " [16.28172  ]\n",
      " [18.48463  ]\n",
      " [26.729717 ]\n",
      " [28.10011  ]\n",
      " [25.73521  ]\n",
      " [31.256512 ]\n",
      " [28.958904 ]\n",
      " [20.22099  ]\n",
      " [18.650585 ]\n",
      " [19.375134 ]\n",
      " [18.685497 ]\n",
      " [19.120708 ]\n",
      " [20.330547 ]\n",
      " [20.963299 ]\n",
      " [15.785441 ]\n",
      " [16.048534 ]\n",
      " [21.137646 ]\n",
      " [19.152477 ]\n",
      " [16.068554 ]\n",
      " [29.014462 ]\n",
      " [26.692455 ]\n",
      " [29.888927 ]\n",
      " [28.816204 ]\n",
      " [25.003048 ]\n",
      " [30.495953 ]\n",
      " [26.469158 ]\n",
      " [30.321514 ]\n",
      " [29.471844 ]\n",
      " [37.119427 ]\n",
      " [45.26399  ]\n",
      " [22.155102 ]\n",
      " [24.922268 ]\n",
      " [25.563488 ]\n",
      " [29.692486 ]\n",
      " [24.858746 ]\n",
      " [15.569865 ]\n",
      " [16.240002 ]\n",
      " [17.73228  ]\n",
      " [20.95158  ]\n",
      " [21.4174   ]\n",
      " [17.971752 ]\n",
      " [28.624462 ]\n",
      " [20.199383 ]\n",
      " [15.303386 ]\n",
      " [20.402142 ]\n",
      " [18.444347 ]\n",
      " [23.709393 ]\n",
      " [20.23396  ]\n",
      " [18.067211 ]\n",
      " [36.78068  ]\n",
      " [15.980144 ]\n",
      " [17.968517 ]\n",
      " [27.11665  ]\n",
      " [31.250408 ]\n",
      " [32.82548  ]\n",
      " [28.369854 ]\n",
      " [30.977367 ]\n",
      " [30.585033 ]\n",
      " [26.595531 ]\n",
      " [33.348095 ]\n",
      " [34.11851  ]\n",
      " [35.825787 ]\n",
      " [39.455303 ]\n",
      " [39.16569  ]\n",
      " [28.898647 ]\n",
      " [27.548992 ]\n",
      " [22.609295 ]\n",
      " [18.151012 ]\n",
      " [29.580975 ]\n",
      " [15.736064 ]\n",
      " [22.753155 ]\n",
      " [16.286694 ]\n",
      " [16.05952  ]\n",
      " [11.75413  ]\n",
      " [15.48289  ]\n",
      " [18.362072 ]\n",
      " [13.240123 ]\n",
      " [19.899456 ]\n",
      " [13.419841 ]\n",
      " [28.853756 ]\n",
      " [28.189236 ]\n",
      " [29.43742  ]\n",
      " [29.558147 ]\n",
      " [22.382824 ]\n",
      " [ 7.8939924]\n",
      " [26.191357 ]\n",
      " [10.303447 ]\n",
      " [27.20985  ]\n",
      " [26.832378 ]\n",
      " [28.294079 ]\n",
      " [29.001354 ]\n",
      " [27.309795 ]\n",
      " [28.90208  ]\n",
      " [29.324627 ]\n",
      " [26.927105 ]\n",
      " [30.022778 ]\n",
      " [26.313992 ]\n",
      " [27.984478 ]\n",
      " [28.551586 ]\n",
      " [27.538097 ]\n",
      " [29.644665 ]\n",
      " [28.942547 ]\n",
      " [17.641918 ]\n",
      " [30.85899  ]\n",
      " [31.052868 ]\n",
      " [28.327618 ]\n",
      " [32.61256  ]\n",
      " [29.004528 ]\n",
      " [28.909618 ]\n",
      " [31.477032 ]\n",
      " [28.977428 ]\n",
      " [23.09834  ]\n",
      " [24.233837 ]\n",
      " [26.97514  ]\n",
      " [25.07362  ]\n",
      " [27.598736 ]\n",
      " [34.976406 ]\n",
      " [27.842358 ]\n",
      " [26.193523 ]\n",
      " [36.572216 ]\n",
      " [43.432323 ]\n",
      " [31.131512 ]\n",
      " [31.55061  ]\n",
      " [28.370708 ]\n",
      " [27.841564 ]\n",
      " [25.96098  ]\n",
      " [27.34013  ]\n",
      " [28.59721  ]\n",
      " [27.504925 ]\n",
      " [26.66212  ]\n",
      " [27.23193  ]\n",
      " [26.952557 ]\n",
      " [27.670696 ]\n",
      " [28.495892 ]\n",
      " [27.592907 ]\n",
      " [28.619396 ]\n",
      " [25.758984 ]\n",
      " [26.451107 ]\n",
      " [27.84245  ]\n",
      " [28.862438 ]\n",
      " [35.375774 ]\n",
      " [29.164349 ]\n",
      " [29.548016 ]\n",
      " [35.892254 ]\n",
      " [28.704601 ]\n",
      " [29.537884 ]\n",
      " [26.097637 ]\n",
      " [32.42506  ]\n",
      " [37.087566 ]\n",
      " [22.573437 ]\n",
      " [ 2.039195 ]\n",
      " [19.827496 ]\n",
      " [17.12196  ]\n",
      " [33.129528 ]\n",
      " [33.379986 ]\n",
      " [32.169964 ]\n",
      " [32.425488 ]\n",
      " [28.22218  ]\n",
      " [28.168438 ]\n",
      " [31.24516  ]\n",
      " [30.44981  ]\n",
      " [27.932934 ]\n",
      " [28.889645 ]\n",
      " [28.651272 ]\n",
      " [25.536175 ]\n",
      " [28.327465 ]\n",
      " [30.474255 ]\n",
      " [29.354748 ]\n",
      " [27.904003 ]\n",
      " [28.54713  ]\n",
      " [28.497112 ]\n",
      " [28.614666 ]\n",
      " [28.387646 ]\n",
      " [ 9.067332 ]\n",
      " [27.377148 ]\n",
      " [20.277447 ]\n",
      " [31.358196 ]\n",
      " [27.644115 ]\n",
      " [29.318005 ]\n",
      " [29.331402 ]\n",
      " [23.500286 ]\n",
      " [27.36073  ]\n",
      " [29.63609  ]\n",
      " [31.019176 ]]\n"
     ]
    }
   ],
   "source": [
    "#Make predictions\n",
    "pred = model.predict(x)\n",
    "print(\"Shape: {}\".format(pred.shape))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 7.727367163327036\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
    "print(f\"Final score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
    "dummies = pd.get_dummies(df['species']) # Classification\n",
    "species = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 1.0870\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.9923\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.9218\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.8771\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.8440\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.8090\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.7750\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.7412\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.7100\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.6778\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.6483\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.6171\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.5844\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.5554\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.5282\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.5034\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4786\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4480\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4211\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.3991\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.3775\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.3613\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.3453\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.3315\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.3188\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.3063\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2950\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2865\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.2815\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.2640\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.2596\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.2459\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.2381\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.2305\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.2231\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.2158\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.2078\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.2043\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1954\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1915\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1832\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1795\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1741\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1684\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1642\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1592\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.1559\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.1523\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.1509\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.1418\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.1443\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.1364\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.1376\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.1336\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.1321\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.1270\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.1252\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.1201\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.1228\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.1179\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.1161\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.1137\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.1129\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.1098\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.1094\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.1060\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.1071\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.1067\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.1041\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.1040\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.1025\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.1027\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0971\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0972\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0951\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0946\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0986\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0914\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0917\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0914\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0889\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0891\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0864\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0929\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0890\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0897\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0868\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0887\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0846\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0829\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0838\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0857\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0812\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0822\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0798\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0791\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0801\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0793\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0766\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x247e377bf98>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(x,y,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: {pred.shape}\n",
      "[[9.98974681e-01 1.02525530e-03 9.08500297e-08]\n",
      " [9.96189415e-01 3.81000433e-03 6.38434187e-07]\n",
      " [9.98228490e-01 1.77120336e-03 3.06117045e-07]\n",
      " [9.95563507e-01 4.43549128e-03 1.09553218e-06]\n",
      " [9.99145627e-01 8.54240498e-04 8.04126685e-08]\n",
      " [9.98863459e-01 1.13639503e-03 7.51284546e-08]\n",
      " [9.98223007e-01 1.77662424e-03 3.55281912e-07]\n",
      " [9.98146415e-01 1.85338885e-03 2.17234899e-07]\n",
      " [9.94361758e-01 5.63633069e-03 1.94435870e-06]\n",
      " [9.96403933e-01 3.59548046e-03 5.52726760e-07]\n",
      " [9.99219775e-01 7.80165603e-04 4.34621086e-08]\n",
      " [9.97216702e-01 2.78280722e-03 4.58235377e-07]\n",
      " [9.96566296e-01 3.43311764e-03 5.99749796e-07]\n",
      " [9.98389244e-01 1.61032367e-03 4.31749299e-07]\n",
      " [9.99854565e-01 1.45371028e-04 3.06884829e-09]\n",
      " [9.99826252e-01 1.73824694e-04 4.65175098e-09]\n",
      " [9.99682426e-01 3.17646278e-04 1.55085313e-08]\n",
      " [9.98867869e-01 1.13198371e-03 1.08840091e-07]\n",
      " [9.98809218e-01 1.19076588e-03 5.29059179e-08]\n",
      " [9.99210119e-01 7.89720973e-04 6.60740156e-08]\n",
      " [9.96780276e-01 3.21946456e-03 2.63308323e-07]\n",
      " [9.98913884e-01 1.08597055e-03 1.05864359e-07]\n",
      " [9.99642253e-01 3.57754063e-04 4.36977245e-08]\n",
      " [9.92869198e-01 7.12960400e-03 1.22635356e-06]\n",
      " [9.92515504e-01 7.48295616e-03 1.56069098e-06]\n",
      " [9.92529929e-01 7.46879540e-03 1.29928549e-06]\n",
      " [9.96673703e-01 3.32582579e-03 5.01328600e-07]\n",
      " [9.98651087e-01 1.34883472e-03 1.12979123e-07]\n",
      " [9.98756170e-01 1.24366861e-03 1.03902387e-07]\n",
      " [9.95353937e-01 4.64503653e-03 1.00958982e-06]\n",
      " [9.94085312e-01 5.91350580e-03 1.22337667e-06]\n",
      " [9.97862041e-01 2.13783863e-03 1.77727600e-07]\n",
      " [9.99666214e-01 3.33742966e-04 1.68276273e-08]\n",
      " [9.99815285e-01 1.84692952e-04 5.87480731e-09]\n",
      " [9.95902240e-01 4.09710081e-03 6.87296563e-07]\n",
      " [9.98814344e-01 1.18554721e-03 1.27361062e-07]\n",
      " [9.99331474e-01 6.68548688e-04 3.23037526e-08]\n",
      " [9.99171376e-01 8.28520220e-04 8.21518427e-08]\n",
      " [9.96801019e-01 3.19804042e-03 9.48383274e-07]\n",
      " [9.98217881e-01 1.78182777e-03 1.83160751e-07]\n",
      " [9.99139428e-01 8.60380998e-04 8.75169732e-08]\n",
      " [9.77355480e-01 2.26328280e-02 1.16645651e-05]\n",
      " [9.97966826e-01 2.03266484e-03 5.22302287e-07]\n",
      " [9.96593893e-01 3.40552069e-03 5.69154508e-07]\n",
      " [9.96879220e-01 3.12037813e-03 3.84415046e-07]\n",
      " [9.95541275e-01 4.45777364e-03 9.27317274e-07]\n",
      " [9.99011040e-01 9.88832326e-04 8.22775803e-08]\n",
      " [9.97454703e-01 2.54469085e-03 5.41417251e-07]\n",
      " [9.99184549e-01 8.15434731e-04 5.18417735e-08]\n",
      " [9.98298585e-01 1.70122727e-03 1.98727122e-07]\n",
      " [7.73089065e-04 9.96870220e-01 2.35663983e-03]\n",
      " [1.50078302e-03 9.90782440e-01 7.71672837e-03]\n",
      " [6.96654897e-04 9.79283929e-01 2.00192947e-02]\n",
      " [2.48042145e-03 8.97802830e-01 9.97167677e-02]\n",
      " [1.05387205e-03 9.53163087e-01 4.57831062e-02]\n",
      " [1.73187128e-03 9.00871396e-01 9.73967090e-02]\n",
      " [1.52593828e-03 9.65985239e-01 3.24888118e-02]\n",
      " [1.24072479e-02 9.81808245e-01 5.78445382e-03]\n",
      " [8.92159063e-04 9.90985513e-01 8.12239572e-03]\n",
      " [4.54466883e-03 9.42755580e-01 5.26998416e-02]\n",
      " [4.13688878e-03 9.71277952e-01 2.45851781e-02]\n",
      " [2.60095927e-03 9.81176853e-01 1.62221286e-02]\n",
      " [1.49669591e-03 9.89682674e-01 8.82065482e-03]\n",
      " [1.21655024e-03 9.04262304e-01 9.45210904e-02]\n",
      " [1.20641403e-02 9.84999716e-01 2.93615111e-03]\n",
      " [1.31140056e-03 9.96501446e-01 2.18719803e-03]\n",
      " [2.22390704e-03 8.38221133e-01 1.59554943e-01]\n",
      " [2.20682891e-03 9.93133247e-01 4.65993769e-03]\n",
      " [6.76054507e-04 5.61315954e-01 4.38007951e-01]\n",
      " [2.57609901e-03 9.89470243e-01 7.95368757e-03]\n",
      " [1.25617022e-03 5.51842213e-01 4.46901590e-01]\n",
      " [2.46939831e-03 9.94154155e-01 3.37644131e-03]\n",
      " [3.84387327e-04 4.22751546e-01 5.76864064e-01]\n",
      " [1.04069314e-03 9.48104858e-01 5.08544110e-02]\n",
      " [1.41973759e-03 9.94964242e-01 3.61606246e-03]\n",
      " [1.21568795e-03 9.95281041e-01 3.50328395e-03]\n",
      " [6.61992468e-04 9.68214214e-01 3.11237164e-02]\n",
      " [6.87385444e-04 7.86541641e-01 2.12770969e-01]\n",
      " [1.70518155e-03 9.19378877e-01 7.89159611e-02]\n",
      " [1.37447016e-02 9.84377027e-01 1.87826483e-03]\n",
      " [2.87796371e-03 9.87728238e-01 9.39375255e-03]\n",
      " [3.71882902e-03 9.90878642e-01 5.40254219e-03]\n",
      " [2.97598727e-03 9.92693305e-01 4.33070073e-03]\n",
      " [1.41324810e-04 1.22214794e-01 8.77643883e-01]\n",
      " [2.30616285e-03 7.41028011e-01 2.56665885e-01]\n",
      " [2.39288923e-03 9.78303134e-01 1.93040408e-02]\n",
      " [9.64517763e-04 9.85946834e-01 1.30887255e-02]\n",
      " [9.82620288e-04 9.25405741e-01 7.36116767e-02]\n",
      " [3.05802864e-03 9.88704026e-01 8.23788065e-03]\n",
      " [2.83640227e-03 9.49840784e-01 4.73228209e-02]\n",
      " [1.80022360e-03 8.65296900e-01 1.32902905e-01]\n",
      " [1.45151722e-03 9.58463013e-01 4.00854535e-02]\n",
      " [2.23315414e-03 9.89838839e-01 7.92809483e-03]\n",
      " [9.70116910e-03 9.84561443e-01 5.73742110e-03]\n",
      " [2.42342521e-03 9.53320026e-01 4.42565605e-02]\n",
      " [2.40872800e-03 9.91580904e-01 6.01038337e-03]\n",
      " [2.49217055e-03 9.82342780e-01 1.51650319e-02]\n",
      " [1.56085147e-03 9.92695570e-01 5.74355759e-03]\n",
      " [4.57927175e-02 9.51487422e-01 2.71983491e-03]\n",
      " [2.59946357e-03 9.83853102e-01 1.35473907e-02]\n",
      " [9.99467488e-07 7.32274668e-04 9.99266684e-01]\n",
      " [2.63642396e-05 1.51844127e-02 9.84789252e-01]\n",
      " [5.96362815e-06 1.38161480e-02 9.86177921e-01]\n",
      " [1.52268103e-05 1.95357800e-02 9.80449021e-01]\n",
      " [2.46010291e-06 2.79011833e-03 9.97207463e-01]\n",
      " [4.91139019e-07 2.34541181e-03 9.97654140e-01]\n",
      " [1.30836619e-04 2.90655270e-02 9.70803618e-01]\n",
      " [2.60641264e-06 1.16678393e-02 9.88329530e-01]\n",
      " [3.19844844e-06 6.25925511e-03 9.93737578e-01]\n",
      " [5.21968786e-06 8.74853414e-03 9.91246283e-01]\n",
      " [4.61928052e-04 3.52635354e-01 6.46902740e-01]\n",
      " [2.94454712e-05 3.20881605e-02 9.67882454e-01]\n",
      " [3.23244785e-05 4.28905003e-02 9.57077146e-01]\n",
      " [1.24724256e-05 5.85053861e-03 9.94136930e-01]\n",
      " [7.07477921e-06 2.48354045e-03 9.97509360e-01]\n",
      " [4.37382914e-05 2.82351691e-02 9.71721113e-01]\n",
      " [6.21445070e-05 8.30827132e-02 9.16855097e-01]\n",
      " [4.07893458e-06 1.94394998e-02 9.80556369e-01]\n",
      " [8.64853433e-08 3.64623702e-04 9.99635220e-01]\n",
      " [4.85453602e-05 5.09810783e-02 9.48970377e-01]\n",
      " [1.22984748e-05 1.62601285e-02 9.83727574e-01]\n",
      " [5.48713615e-05 2.03588400e-02 9.79586303e-01]\n",
      " [3.68170390e-07 2.09340127e-03 9.97906208e-01]\n",
      " [3.11443058e-04 2.47569412e-01 7.52119124e-01]\n",
      " [2.97031493e-05 3.79642025e-02 9.62006032e-01]\n",
      " [3.45129629e-05 1.11041382e-01 8.88924122e-01]\n",
      " [5.80681197e-04 3.78613800e-01 6.20805502e-01]\n",
      " [6.22806139e-04 3.75590861e-01 6.23786390e-01]\n",
      " [3.84119176e-06 4.05753171e-03 9.95938659e-01]\n",
      " [8.96629790e-05 3.13560516e-01 6.86349809e-01]\n",
      " [3.67290772e-06 1.59396064e-02 9.84056711e-01]\n",
      " [6.35361648e-05 3.29886496e-01 6.70049965e-01]\n",
      " [2.84599832e-06 2.71091075e-03 9.97286201e-01]\n",
      " [4.05449304e-04 4.65204209e-01 5.34390390e-01]\n",
      " [2.01535804e-05 3.02108601e-02 9.69768941e-01]\n",
      " [2.75576963e-06 1.02465907e-02 9.89750683e-01]\n",
      " [9.35236767e-06 6.02843240e-03 9.93962228e-01]\n",
      " [7.67688834e-05 9.11502764e-02 9.08773005e-01]\n",
      " [8.30882345e-04 4.27294761e-01 5.71874380e-01]\n",
      " [1.02803315e-04 1.31242409e-01 8.68654788e-01]\n",
      " [5.95409574e-06 5.93486149e-03 9.94059205e-01]\n",
      " [2.29522644e-04 1.95809379e-01 8.03961098e-01]\n",
      " [2.63642396e-05 1.51844127e-02 9.84789252e-01]\n",
      " [3.10505015e-06 4.41582967e-03 9.95581090e-01]\n",
      " [5.04517902e-06 4.63961763e-03 9.95355368e-01]\n",
      " [6.20852588e-05 5.08288443e-02 9.49109018e-01]\n",
      " [5.73832549e-05 4.91654240e-02 9.50777173e-01]\n",
      " [1.42644742e-04 1.27439827e-01 8.72417450e-01]\n",
      " [3.77708639e-05 2.08228100e-02 9.79139447e-01]\n",
      " [1.75207024e-04 1.05600536e-01 8.94224286e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "pred = model.predict(x)\n",
    "print(\"Shape: {pred.shape}\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Expected: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Usually the column (pred) with the highest prediction is considered to be the prediction of the neural network.  It is easy\n",
    "# to convert the predictions to the expected iris species.  The argmax function finds the index of the maximum prediction\n",
    "# for each row.\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "expected_classes = np.argmax(y,axis=1)\n",
    "print(f\"Predictions: {predict_classes}\")\n",
    "print(f\"Expected: {expected_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-setosa',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-virginica',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-virginica',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica',\n",
       " 'Iris-virginica']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[species[i] for i in predict_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Accuracy might be a more easily understood error metric.  It is essentially a test score.  For all of the iris predictions,\n",
    "# what percent were correct?  The downside is it does not consider how confident the neural network was in each prediction.\n",
    "correct = accuracy_score(expected_classes,predict_classes)\n",
    "print(f\"Accuracy: {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.3: Saving and Loading a Keras Neural Network\n",
    "Complex neural networks will take a long time to fit/train. It is helpful to be able to save these neural networks so that they can be reloaded later. A reloaded neural network will not require retraining. Keras provides three formats for neural network saving.\n",
    "\n",
    "YAML - Stores the neural network structure (no weights) in the YAML file format.\n",
    "JSON - Stores the neural network structure (no weights) in the JSON file format.\n",
    "HDF5 - Stores the complete neural network (with weights) in the HDF5 file format. Do not confuse HDF5 with HDFS. They are different. We do not use HDFS in this class.\n",
    "Usually you will want to save in HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \".\"\n",
    "# Save neural network structure to JSON (no weights)\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save neural network structure to YAML (no weights)\n",
    "model_yaml = model.to_yaml()\n",
    "with open(os.path.join(save_path,\"network.yaml\"), \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "# Save entire network to HDF5 (save everything, suggested)\n",
    "model.save(os.path.join(save_path,\"network.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After load score (RMSE): 0.11395354568958282\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model(os.path.join(save_path,\"network.h5\"))\n",
    "pred = model2.predict(x)\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
    "print(f\"After load score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
