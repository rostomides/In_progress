{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 10} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor Flow Version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Larbi\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/1000\n",
      " - 1s - loss: 1.0498 - val_loss: 1.0414\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 0.9917 - val_loss: 0.9949\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 0.9678 - val_loss: 0.9608\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 0.9365 - val_loss: 0.9306\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 0.9089 - val_loss: 0.9123\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.8921 - val_loss: 0.8909\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.8669 - val_loss: 0.8540\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.8454 - val_loss: 0.8297\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.8253 - val_loss: 0.8096\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.8038 - val_loss: 0.7913\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.7905 - val_loss: 0.7716\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.7668 - val_loss: 0.7489\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.7513 - val_loss: 0.7280\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.7308 - val_loss: 0.7080\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.7137 - val_loss: 0.6969\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 0.7003 - val_loss: 0.6735\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.6777 - val_loss: 0.6479\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.6605 - val_loss: 0.6259\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.6424 - val_loss: 0.6065\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.6243 - val_loss: 0.5891\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.6084 - val_loss: 0.5704\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.5942 - val_loss: 0.5520\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.5757 - val_loss: 0.5355\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.5624 - val_loss: 0.5204\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 0.5463 - val_loss: 0.5013\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.5308 - val_loss: 0.4858\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.5171 - val_loss: 0.4726\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 0.5052 - val_loss: 0.4615\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 0.4930 - val_loss: 0.4479\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 0.4811 - val_loss: 0.4330\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 0.4691 - val_loss: 0.4206\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 0.4623 - val_loss: 0.4081\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 0.4466 - val_loss: 0.3987\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 0.4379 - val_loss: 0.3903\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 0.4267 - val_loss: 0.3770\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 0.4169 - val_loss: 0.3678\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 0.4079 - val_loss: 0.3590\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 0.3988 - val_loss: 0.3509\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 0.3912 - val_loss: 0.3435\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.3811 - val_loss: 0.3349\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.3741 - val_loss: 0.3272\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 0.3665 - val_loss: 0.3201\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 0.3597 - val_loss: 0.3180\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 0.3528 - val_loss: 0.3061\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 0.3485 - val_loss: 0.3007\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 0.3411 - val_loss: 0.2925\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 0.3308 - val_loss: 0.2874\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 0.3240 - val_loss: 0.2837\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 0.3210 - val_loss: 0.2757\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 0.3163 - val_loss: 0.2707\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 0.3054 - val_loss: 0.2657\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.3056 - val_loss: 0.2595\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.2944 - val_loss: 0.2562\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.2907 - val_loss: 0.2499\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.2820 - val_loss: 0.2412\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.2743 - val_loss: 0.2360\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.2683 - val_loss: 0.2374\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.2671 - val_loss: 0.2260\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.2555 - val_loss: 0.2202\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.2531 - val_loss: 0.2153\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.2468 - val_loss: 0.2120\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.2431 - val_loss: 0.2064\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.2360 - val_loss: 0.2029\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.2304 - val_loss: 0.1979\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.2255 - val_loss: 0.1934\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.2243 - val_loss: 0.1887\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.2159 - val_loss: 0.1912\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.2160 - val_loss: 0.1828\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.2096 - val_loss: 0.1783\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.2026 - val_loss: 0.1738\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.2006 - val_loss: 0.1702\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.1983 - val_loss: 0.1671\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.1952 - val_loss: 0.1720\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.1968 - val_loss: 0.1606\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.1852 - val_loss: 0.1587\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.1810 - val_loss: 0.1552\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.1783 - val_loss: 0.1524\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.1760 - val_loss: 0.1525\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.1725 - val_loss: 0.1465\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.1692 - val_loss: 0.1441\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.1675 - val_loss: 0.1421\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.1634 - val_loss: 0.1401\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.1608 - val_loss: 0.1366\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.1580 - val_loss: 0.1359\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.1579 - val_loss: 0.1349\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.1517 - val_loss: 0.1299\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.1521 - val_loss: 0.1278\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.1480 - val_loss: 0.1310\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.1494 - val_loss: 0.1285\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.1438 - val_loss: 0.1222\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.1449 - val_loss: 0.1201\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.1444 - val_loss: 0.1235\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.1365 - val_loss: 0.1168\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.1361 - val_loss: 0.1154\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.1360 - val_loss: 0.1136\n",
      "Epoch 96/1000\n",
      " - 0s - loss: 0.1372 - val_loss: 0.1168\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.1301 - val_loss: 0.1104\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.1303 - val_loss: 0.1090\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.1275 - val_loss: 0.1118\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.1264 - val_loss: 0.1083\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.1351 - val_loss: 0.1053\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.1217 - val_loss: 0.1171\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.1288 - val_loss: 0.1119\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.1227 - val_loss: 0.1013\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.1222 - val_loss: 0.1000\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.1190 - val_loss: 0.1003\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.1158 - val_loss: 0.0986\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.1151 - val_loss: 0.0981\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.1163 - val_loss: 0.1007\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.1122 - val_loss: 0.0957\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.1128 - val_loss: 0.0937\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.1121 - val_loss: 0.0953\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.1107 - val_loss: 0.0937\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.1109 - val_loss: 0.0908\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.1081 - val_loss: 0.0930\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.1065 - val_loss: 0.0959\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.1065 - val_loss: 0.0912\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.1049 - val_loss: 0.0881\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.1042 - val_loss: 0.0875\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.1050 - val_loss: 0.0913\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.1015 - val_loss: 0.0857\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.1061 - val_loss: 0.0844\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.0993 - val_loss: 0.0924\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.1089 - val_loss: 0.0944\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.1011 - val_loss: 0.0824\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.0996 - val_loss: 0.0820\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.0972 - val_loss: 0.0857\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.0981 - val_loss: 0.0886\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.0973 - val_loss: 0.0821\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.0946 - val_loss: 0.0795\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.1015 - val_loss: 0.0788\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.0955 - val_loss: 0.0817\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.0973 - val_loss: 0.0952\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.0973 - val_loss: 0.0812\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.1031 - val_loss: 0.0776\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.0945 - val_loss: 0.0827\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.0951 - val_loss: 0.0864\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.0927 - val_loss: 0.0778\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.0960 - val_loss: 0.0746\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.0898 - val_loss: 0.0823\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.0945 - val_loss: 0.0958\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.0914 - val_loss: 0.0748\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.0969 - val_loss: 0.0775\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.0983 - val_loss: 0.0725\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.0927 - val_loss: 0.0962\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.0965 - val_loss: 0.0764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000\n",
      " - 0s - loss: 0.0897 - val_loss: 0.0710\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.0880 - val_loss: 0.0719\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.0897 - val_loss: 0.0776\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.0859 - val_loss: 0.0704\n",
      "Epoch 151/1000\n",
      " - 0s - loss: 0.0869 - val_loss: 0.0709\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.0855 - val_loss: 0.0696\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.0847 - val_loss: 0.0714\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.0834 - val_loss: 0.0764\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.0851 - val_loss: 0.0742\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.0831 - val_loss: 0.0690\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.0839 - val_loss: 0.0678\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.0901 - val_loss: 0.0673\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.0839 - val_loss: 0.0733\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.0834 - val_loss: 0.0808\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.0850 - val_loss: 0.0732\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.0814 - val_loss: 0.0671\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00162: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f3b81fa9b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
    "dummies = pd.get_dummies(df['species']) # Classification\n",
    "species = dummies.columns\n",
    "y = dummies.values\n",
    "\n",
    "# Split into validation and training sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Build neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', \n",
    "                        min_delta=1e-3, \n",
    "                        patience=5, #number of epochs with no improvement after which training will be stopped.\n",
    "                        verbose=1, \n",
    "                        mode='auto',\n",
    "                        restore_best_weights=True\n",
    "                       )\n",
    "model.fit(x_train,y_train,\n",
    "          validation_data=(x_test,y_test),\n",
    "          callbacks=[monitor],\n",
    "          verbose=2,\n",
    "          epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "expected_classes = np.argmax(y_test,axis=1)\n",
    "correct = accuracy_score(expected_classes,predict_classes)\n",
    "print(f\"Accuracy: {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 298 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      " - 0s - loss: 133319.1233 - val_loss: 74561.6619\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 59004.5239 - val_loss: 40118.5272\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 30929.2186 - val_loss: 20519.2127\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 15532.6567 - val_loss: 10110.0346\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 7663.1073 - val_loss: 5100.4461\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 3909.4979 - val_loss: 2696.3969\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 2100.7387 - val_loss: 1755.6884\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 1471.6494 - val_loss: 1290.4503\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 893.4462 - val_loss: 265.6893\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 245.0630 - val_loss: 166.4855\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 178.0845 - val_loss: 106.4734\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 132.3489 - val_loss: 109.6739\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 126.9353 - val_loss: 109.7395\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 126.6941 - val_loss: 107.3153\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 137.4892 - val_loss: 145.8468\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 133.0432 - val_loss: 102.3151\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 125.5752 - val_loss: 101.5785\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 130.6192 - val_loss: 101.0529\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 121.8774 - val_loss: 113.8223\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 129.9630 - val_loss: 97.5751\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 119.3324 - val_loss: 99.0638\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 118.1419 - val_loss: 97.7156\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 116.8198 - val_loss: 94.9919\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 116.4978 - val_loss: 101.7009\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 129.0440 - val_loss: 94.9102\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 120.3535 - val_loss: 92.1133\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 117.1204 - val_loss: 93.4802\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 114.0985 - val_loss: 118.0323\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 121.9955 - val_loss: 104.2767\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 116.3281 - val_loss: 89.2614\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 109.0412 - val_loss: 102.3613\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 111.9448 - val_loss: 94.2253\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 107.3596 - val_loss: 86.1437\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 109.5197 - val_loss: 85.3874\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 108.0127 - val_loss: 94.5936\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 104.6383 - val_loss: 83.7419\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 105.5003 - val_loss: 87.5923\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 104.9289 - val_loss: 95.2404\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 108.1734 - val_loss: 82.1631\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 102.0540 - val_loss: 82.7992\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 101.8100 - val_loss: 80.4157\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 100.9984 - val_loss: 79.6951\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 98.9613 - val_loss: 92.7136\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 102.3565 - val_loss: 84.7716\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 105.0831 - val_loss: 82.6187\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 101.3703 - val_loss: 77.4065\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 101.1816 - val_loss: 79.9624\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 103.5161 - val_loss: 80.3168\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 95.9639 - val_loss: 88.8617\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 97.0657 - val_loss: 79.8138\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 93.6395 - val_loss: 76.8049\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 92.1426 - val_loss: 107.6909\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 105.2358 - val_loss: 74.4350\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 96.2005 - val_loss: 77.4066\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 95.6803 - val_loss: 72.5946\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 89.6747 - val_loss: 71.9211\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 89.8209 - val_loss: 78.5488\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 89.2348 - val_loss: 77.8323\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 91.1090 - val_loss: 69.9328\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 89.6043 - val_loss: 69.6474\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 86.4303 - val_loss: 71.8004\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 87.6915 - val_loss: 68.5692\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 85.8567 - val_loss: 68.4671\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 85.7857 - val_loss: 76.4655\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 84.8989 - val_loss: 75.2976\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 84.1608 - val_loss: 66.5370\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 83.7650 - val_loss: 67.6387\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 84.0832 - val_loss: 65.3254\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 79.0517 - val_loss: 88.4321\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 90.1347 - val_loss: 93.2354\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 83.9553 - val_loss: 64.5957\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 83.2332 - val_loss: 65.7872\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 82.6268 - val_loss: 62.7427\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 83.4387 - val_loss: 66.9883\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 80.6780 - val_loss: 68.5777\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 80.4480 - val_loss: 93.4405\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 87.9200 - val_loss: 81.3987\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 86.7535 - val_loss: 62.9187\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00078: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4418d84e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "cars = df['name']\n",
    "\n",
    "# Handle missing value\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "\n",
    "# Pandas to Numpy\n",
    "x = df[['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "       'acceleration', 'year', 'origin']].values\n",
    "y = df['mpg'].values # regression\n",
    "\n",
    "# Split into validation and training sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(1)) # Output\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)\n",
    "model.fit(x_train,y_train,\n",
    "          validation_data=(x_test,y_test),\n",
    "          callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 7.921030120694821\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(f\"Final score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
